{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch\n",
    "import torch.nn.init\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from copy import deepcopy, copy\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p11 = [[81,123], [594,409], [848,504], [167,212], [983,300], [146,581], [57,482],   [242,494], [213,56], [944,639] ]\n",
    "p12 = [[126,131],[609,412], [857,508], [200,216], [1017,302],[177,579], [97,480],   [268,494], [251,63], [966,647] ]\n",
    "p21 = [[95,303], [309,433], [36,176],  [419,192], [623,451], [575,224], [157,176],  [73,536],  [398,75], [229,145] ]\n",
    "p22 = [[118,302],[318,433], [70,175],  [451,191], [639,450], [605,223], [192,175],  [72,536],  [418,74], [265,144] ]\n",
    "p31 = [[135,50], [52,253],  [165,164], [170,28],  [289,78],  [253,293], [386,112],  [418,11],  [223,197],[418,211] ]\n",
    "p32 = [[100,49], [58,253],  [159,162], [135,27],  [255,78],  [236,293], [351,112],  [383,12],  [215,196],[383,211] ]\n",
    "p41 = [[22,152], [109,149], [87,340],  [438,498], [259,504], [448,679], [355,619],  [479,145], [259,153],[196,358] ]\n",
    "p42 = [[10,163], [108,139], [83,349],  [515,530], [301,537], [539,756], [468,657],  [521,149], [282,138],[217,363] ]\n",
    "p51 = [[96,236], [366,36],  [314,554], [105,1087],[531,1118],[978,798], [1180,1028],[1192,482],[818,129],[1118,240]]\n",
    "p52 = [[170,239],[441,41],  [388,557], [172,1089],[601,1118],[1052,800],[1254,1030],[1266,485],[893,133],[1193,244]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = 5  # select between 5 pairs of images (1~5)\n",
    "\n",
    "if choose == 1:\n",
    "    path_p = 'Stereo_images/image11.png'\n",
    "    path_q = 'Stereo_images/image12.png'\n",
    "    p = p11\n",
    "    q = p12\n",
    "    save = '1_'\n",
    "    txtName1 = 't1_1.txt'\n",
    "    txtName2 = 't1_2.txt'\n",
    "elif choose == 2:\n",
    "    path_p = 'Stereo_images/image21.png'\n",
    "    path_q = 'Stereo_images/image22.png'    \n",
    "    p = p21\n",
    "    q = p22\n",
    "    save = '2_'\n",
    "    txtName1 = 't2_1.txt'\n",
    "    txtName2 = 't2_2.txt'\n",
    "elif choose == 3:\n",
    "    path_p = 'Stereo_images/image31.png'\n",
    "    path_q = 'Stereo_images/image32.png'    \n",
    "    p = p31\n",
    "    q = p32\n",
    "    save = '3_'\n",
    "    txtName1 = 't3_1.txt'\n",
    "    txtName2 = 't3_2.txt'\n",
    "elif choose == 4:\n",
    "    path_p = 'Stereo_images/image41.png'\n",
    "    path_q = 'Stereo_images/image42.png'    \n",
    "    p = p41\n",
    "    q = p42\n",
    "    save = '4_'\n",
    "    txtName1 = 't4_1.txt'\n",
    "    txtName2 = 't4_2.txt'\n",
    "elif choose == 5:\n",
    "    path_p = 'Stereo_images/image51.png'\n",
    "    path_q = 'Stereo_images/image52.png'    \n",
    "    p = p51\n",
    "    q = p52\n",
    "    save = '5_'\n",
    "    txtName1 = 't5_1.txt'\n",
    "    txtName2 = 't5_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_keypoints:  torch.Size([5, 100, 2])\n",
      "q_keypoints:  torch.Size([5, 100, 2])\n"
     ]
    }
   ],
   "source": [
    "p_point = torch.load(\"p_keypoints.pt\")\n",
    "q_point = torch.load(\"q_keypoints.pt\")\n",
    "print(\"p_keypoints: \", p_point.shape)\n",
    "print(\"q_keypoints: \", q_point.shape)\n",
    "\n",
    "def plotDesc(point, path, color):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in range(len(point[choose-1])):\n",
    "        x_list.append(point[choose-1][i][0])\n",
    "        y_list.append(point[choose-1][i][1])\n",
    "\n",
    "    im = plt.imread(path)\n",
    "    implot = plt.imshow(im)\n",
    "    plt.plot(x_list, y_list, color)\n",
    "    plt.show()    \n",
    "\n",
    "# # plot image 1 \n",
    "# plotDesc(p_point, path_p, 'b.') \n",
    "# # plot image 2\n",
    "# plotDesc(q_point, path_q, 'r.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of C: (100, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "p_des = torch.load(\"p_description.pt\")  # torch.Size([5, 100, 128])\n",
    "q_des = torch.load(\"q_description.pt\")  # torch.Size([5, 100, 128])\n",
    "p_point = np.array(p_point)\n",
    "q_point = np.array(q_point)\n",
    "\n",
    "data = np.zeros((100, 100))\n",
    "pair_matrix = data.tolist()\n",
    "cost_matrix = torch.tensor(data)\n",
    "\n",
    "for i in range(len(p_des[choose-1])):       # 100\n",
    "    for j in range(len(q_des[choose-1])):   # 100\n",
    "        pair_matrix[i][j] = (p_point[choose-1][i].tolist(), q_point[choose-1][j].tolist())\n",
    "        cost_matrix[i][j] = torch.dist(p_des[choose-1][i], q_des[choose-1][j], p=2)\n",
    "\n",
    "cost_matrix_np = cost_matrix.detach().numpy()\n",
    "row_ind, col_ind = linear_sum_assignment(cost_matrix_np)   # Hungarian\n",
    "\n",
    "# C: one-to-one matching pairs\n",
    "c = []\n",
    "for i in range(len(col_ind)):\n",
    "    c.append(pair_matrix[i][col_ind[i]])\n",
    "    c[i][0].append(1)\n",
    "    c[i][1].append(1)\n",
    "# print(\"\\nC:\\n\", c)    \n",
    "print(\"shape of C:\", np.shape(c))    # (100, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFromC(c, idx, path, color):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in range(len(c)):\n",
    "        x_list.append(c[i][idx][0])\n",
    "        y_list.append(c[i][idx][1])\n",
    "    im = plt.imread(path)\n",
    "    implot = plt.imshow(im)\n",
    "    plt.plot(x_list, y_list, color)\n",
    "    plt.show()\n",
    "\n",
    "# # plot image 1 \n",
    "# plotFromC(c, 0, path_p, 'b.')\n",
    "# # plot image 2 \n",
    "# plotFromC(c, 1, path_q, 'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(txtName1, \"w\")\n",
    "\n",
    "for i, item in enumerate(c):\n",
    "    f.write('{:>20}  {:>20}\\n'.format(str(item[0][0]), str(item[0][1])))\n",
    "    \n",
    "f.close()\n",
    "\n",
    "f = open(txtName2, \"w\")\n",
    "\n",
    "for i, item in enumerate(c):\n",
    "    f.write('{:>20}  {:>20}\\n'.format(str(item[1][0]), str(item[1][1])))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
