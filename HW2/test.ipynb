{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import os\n",
    "\n",
    "# a = np.array([[1,2,3]])\n",
    "# b= np.array([[4,5,6]])\n",
    "\n",
    "# # out = np.multiply(np.transpose(a), b)\n",
    "# out = np.tensordot(a, b)\n",
    "# print(out)\n",
    "\n",
    "# data = np.zeros((3, 3))\n",
    "# cost = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# row_ind, col_ind = linear_sum_assignment(cost)\n",
    "# final_cost = cost[row_ind, col_ind].sum()\n",
    "# print(row_ind, col_ind)\n",
    "# for i, m in enumerate(row_ind):\n",
    "#     for n in col_ind:\n",
    "#         data[m][n] = 1\n",
    "# print(data)\n",
    "\n",
    "# a = np.zeros((3,3))\n",
    "# a[1][2] = 5\n",
    "# print(a)\n",
    "\n",
    "# a = torch.zeros(1,5)\n",
    "# b = torch.ones(1,5)\n",
    "# print(a, b)\n",
    "# a[0][3] = a[0][0] - b[0][0]\n",
    "# print(a)\n",
    "\n",
    "# data = np.zeros((3, 3840))\n",
    "# cost_vertex = torch.tensor(data)\n",
    "\n",
    "# print(cost_vertex)\n",
    "# print(cost_vertex.numpy())\n",
    "\n",
    "# a = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# print(a)\n",
    "# # out = np.linalg.norm(a,ord=2,keepdims=True)\n",
    "# # out = np.exp(-a)\n",
    "# a[a>3] = 10\n",
    "\n",
    "# print(a)\n",
    "\n",
    "# with open(\"./image_retrieval/ground_truth.txt\") as f:\n",
    "#     tmp = None \n",
    "    \n",
    "#     for line in f:\n",
    "#         if line.startswith('#'):\n",
    "#             continue\n",
    "#         line = line.split()\n",
    "#         if line == []:\n",
    "#             continue\n",
    "#         print(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# a = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# out = sum(a[a<3])\n",
    "# print(a)\n",
    "# print(out)\n",
    "\n",
    "# a = np.array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])\n",
    "# a = a.argsort()[-4:][::-1]\n",
    "# print(a)\n",
    "# a = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# ind = np.argpartition(a, -4)[-4:]\n",
    "# # ind[::-1].sort()\n",
    "# print(ind)\n",
    "# # out = a[ind]\n",
    "# # out[::-1].sort()\n",
    "# # print(out)\n",
    "\n",
    "# i = [4,5,99]\n",
    "# # a = np.array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])\n",
    "# for idx in i:\n",
    "#     if 3 < idx < 3+4:\n",
    "#         print(idx)\n",
    "\n",
    "# s_one = 0\n",
    "# a = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# for i in range(len(a)):\n",
    "#     s_one = np.exp(a[i][i])\n",
    "#     print(s_one)\n",
    "\n",
    "# a = np.array([[4, 1, 3], [2, 0, 5], [3, 2, 2]])\n",
    "# b = np.array([[1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
    "# out = a * -b\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([175, 30, 128])\n",
      "torch.Size([35, 140])\n",
      "torch.Size([35, 140])\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "\n",
    "feature = torch.load(\"feature_descriptors.pt\")  \n",
    "sim_one = torch.load(\"similarity_one.pt\") \n",
    "sim_many = torch.load(\"similarity_many.pt\") \n",
    "\n",
    "print(feature.shape)\n",
    "print(sim_one.shape)\n",
    "print(sim_many.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16.1790, 16.3082, 15.7836, 11.1153,  9.5592,  9.3734,  9.2023,  9.3026,\n",
      "         9.3519,  9.4544,  9.6259,  9.5271,  9.6742,  9.4333,  9.6710,  9.6219,\n",
      "         9.7848,  9.5834,  9.7543,  9.6708,  9.7072,  9.5541,  9.4480,  9.7977,\n",
      "         9.5583,  9.6267,  9.5319,  9.5531,  9.2337,  9.1780,  9.4617,  9.3817,\n",
      "         9.3584,  9.4758,  9.3776,  9.2899,  9.2077,  9.4928,  9.2590,  9.3192,\n",
      "         9.2164,  9.0528,  9.0683,  8.9965,  9.3724,  9.2527,  8.8293,  9.1612,\n",
      "         9.4623,  9.6075,  9.3474,  9.9315,  9.2892,  9.2942,  9.3740,  9.4334,\n",
      "         9.3241,  9.4165,  9.4041,  9.3973,  9.4121,  9.3324,  9.4168,  9.3067,\n",
      "         8.7247,  8.9865,  8.9786,  9.0377,  9.3109,  9.0223,  9.0838,  9.0775,\n",
      "         9.4860,  9.4219,  9.4466,  9.4489,  9.3947,  9.3683,  9.5384,  9.1506,\n",
      "         9.0334,  9.1085,  9.3595,  9.1807,  9.1019,  9.1870,  9.1801,  9.2825,\n",
      "         9.2772,  9.2226,  9.2411,  9.6295,  9.6401,  9.2516,  9.6330,  9.6019,\n",
      "         8.2510,  9.0351,  8.6121,  8.8374,  9.1026,  8.8759,  9.0319,  9.1630,\n",
      "         9.0852,  8.8859,  9.1856,  8.9362,  9.5581,  9.2006,  9.6206,  9.4695,\n",
      "         9.5240,  9.4653,  9.5943,  9.3810,  9.4342,  9.3895,  9.3214,  9.6738,\n",
      "         9.9563,  9.8066,  9.6397,  9.7736,  9.4612,  9.3324,  9.4311,  9.2210,\n",
      "         9.3177,  9.1661,  9.2024,  9.3606,  9.1552,  9.2140,  9.2342,  9.3473,\n",
      "         9.5904,  9.3127,  9.5184,  9.5956], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(sim_one[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
